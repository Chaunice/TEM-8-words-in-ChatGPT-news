Real conversations. Ideas that matter. So many book recommendations.
Listen to “The Ezra Klein Show”
: 
Apple Podcasts
, 
Spotify
, 
Pocket Casts
, 
Google Podcasts
, 
Stitcher
, 
How to Listen
Every Tuesday and Friday, Ezra Klein invites you into a conversation about something that matters, like today’s episode with Adrian Tchaikovsky. Listen 
wherever you get your podcasts
.
Transcripts of our episodes are made available as soon as possible. They are not fully edited for grammar or spelling.
Is A.I. Actually Creative? Are We?
The science fiction writer Adrian Tchaikovsky explores what an explosion of A.I.-produced content would mean for human society and the human spirit.
transcript
bars
0:00/1:05:00
-1:05:00
transcript
Is A.I. Actually Creative? Are We?
The science fiction writer Adrian Tchaikovsky explores what an explosion of A.I.-produced content would mean for human society and the human spirit.
ezra klein
I’m Ezra Klein. This is “The Ezra Klein Show.”
[MUSIC]
So a while back I did an episode on octopuses and I immediately got all these emails from you saying, have you read Adrian Tchaikovsky’s “Children of Ruin?” “Children of Ruin,” when I looked it up, turns out to be a sci-fi book about an advanced civilization built by octopuses, which sold — completely sold immediately on that.
And so I bought it and I started reading it. And then I realized you had to first read the other book in the series, “Children of Time,” which is an advanced civilization built by spiders. And that’s, of course, the second best description of any book I’ve ever read after the octopus one. So I stopped where I was, I got that, and I never looked back.
And I loved these books. They really work through this question of what a civilization built by a very different kind of creature that has a very different sensorium would look like. These books leave you, as the human being reading them, very much feeling like the other, feeling like the one whose mind and hands and society are the clumsy imitation. It’s just a wonderful act of self-alienation.
And for about a year after I read them, every time I would read a normal fiction book about some creative types living in New York, struggling with their creative type problems, I would just have this thought running through my head. I mean, that’s all interesting, but it’s not advanced civilization built around spiders-level interesting. But that didn’t exactly lend itself to a show.
And then Tchaikovsky brought out his new book, “Children of Memory.” And this one is about corvids, about a kind of bird, or at least that’s what it is supposed to be about. But I wasn’t alone in finding it to be an almost astonishingly good book about A.I. It came out right about the time ChatGPT was blowing up.
And “Children of Memory,” whether it was intended or not, it is the single best piece of fiction I’ve read on what it is like — the confusion, the disorientation of interacting with a problem-solving erudite, brilliant, trained to some degree on humans, but not necessarily sanctioned A.I., and also, to the extent this sentence makes any sense, what it might be like to be one.
What Tchaikovsky is remarkable at doing across all these books is imagining how other kinds of minds and other kinds of ways of experiencing the world lead to other worlds, and then thinking about what finding those worlds would do to human beings and the way we experience our world and ourselves. And so this conversation is about that. We talk a bit about spiders and octopuses and corvids, because I don’t think we should forget that even before A.I., we inhabited and inhabit a world with many remarkable minds, very unlike our own. But the core of this conversation is about A.I., and particularly what it will mean for humanity’s sense of our minds, of our capacities, of what makes us us.
Last thing, I talk a bit about a sci-fi story in here that I could not remember the name of. Our amazing fact-checker, Michelle Harris, found it. It is “Melancholy Elephants” by Spider Robinson. And we will put a link to that in Show Notes. As always, if you’ve got any suggestions, guest ideas, feedback to send us, ezrakleinshow@nytimes.com.
[MUSIC]
Adrian Tchaikovsky, welcome to the show.
adrian tchaikovsky
Hello. Thank you very much.
ezra klein
So the first book in your “Children of Time” series centers around a planet where an advanced civilization was built by spiders. Why spiders?
adrian tchaikovsky
The book is about empathy and is about empathy for the other — that is the main theme of the series as a whole. And there’s nothing in the world that people hate more than spiders. If you go on social media with a post about spiders, someone will respond saying, you now have to burn the house down. And so if you can make people empathize with spiders, you can make people empathize for anything.
ezra klein
But I’ve heard you say that you begin in all of these books trying to understand the sensorium of the animal or the insect under consideration. So tell me how would you describe the way a spider senses the world.
adrian tchaikovsky
So the Portia spiders, which I’m using, are very, very visual creatures, and they have that in common with us. So they are very sight-based, very motion-based. But at the same time, spiders have an enormously well-developed sense of vibration.
So the way these spiders communicate, a lot of it is through visual signaling and it’s through a vibrational sense. So they dance, which is something that spiders do for various purposes in the real world, but they dance to communicate and the patterns of vibration allow them to speak to one another.
And at the same time, they have a very highly developed chemical sense. So the spider — the ability to taste through the various sensory organs and hairs and so forth is very acute. And that then becomes a base of their technology. So they have this ability to do a scientific alchemy just freehand.
And of course, with web-spinning, that gives them a technological advantage that a lot of creatures wouldn’t have. And that they can create containers and tools and simple machines, even just with the stuff that comes out of their bodies.
ezra klein
Tell me about how you solve the problem of language, and particularly language that can reach many spiders or inhabitants of the city at once in the book.
adrian tchaikovsky
So they have a simple visual language, which can reach over distances. But, yes, the problem with your vibrational language is it’s obviously rather limited. And of course, it’s a problem that spiders have already solved, because that’s what your web is for. Your spider web is not just for catching prey. It is a kind of an extended sensory organ to send and receive signals.
And so if you get a bunch of spiders on a web, you can speak to the crowd from the center of the web. And then individuals can send signals back to you. And with a sort of finesse of a creature that’s had a long time to evolve this practice, you could have, effectively, multiple conversations going on down different strands, just as you would have the crowd of people talking in a bar, for example.
ezra klein
I lived in a home in Oakland for a couple of years that was absolutely entombed in spiders and spider webs.
Not in a normal way. I mean, we would have conversations with friends that was — do you have spiders in the back? Yeah, we get some spiders. I mean, but like everywhere, like your whole thing is covered in webs? And you would — if anything happened that got rid of the webs, like a rain, they’d be back the next day.
And their just complexity and the speed with which they could create them was a complete marvel to me. And I think it also speaks a little bit to why people are unusually afraid of spiders. There’s something very otherworldly about the spider web and that act of creation and trapping.
So tell me a little bit more about webs. When you did this research, there’s what the spiders can do and then there’s what they build, because they are building species in this very intense way. How do you understand the relationship to webs?
adrian tchaikovsky
There’s been research, certainly since I wrote the book, that’s exploring the full complexity of the spider web. And the idea that the web is something that spiders actually use to export part of their cognitive load in the same way that I use my — my phone is basically where I keep most of my memory of what I’m supposed to be doing at any time.
A spider’s web is doing a lot of the thinking for the spider in the way it constructs it and in the way the vibrations move along it. So that they’re almost bootstrapping their own intelligence because of what they can build.
And in the book, the webs become very much not just the focus of how they construct their technology — so they develop, effectively, a very advanced society without ever really getting to grips with things like fire or the wheel. So a lot of human mainstays they don’t have. But they also they don’t need because they work through a far more of a chemical synthesis and biotech solution because of their own peculiar sensory abilities and their own physical capacity.
But the web also informs the way that they interact with each other in the world. So they — to the spiders in the book, the idea of being connected to anything, to everything, the idea of everything influencing everything else is far more prevalent. So they have less of a bullish attitude towards the world than, historically, humans have often had, and therefore, more to do with, well, how can we make things fit in and work as part of our systems.
ezra klein
So the second book in the series is “Children of Ruin.” One of the main things it’s about is a society that built up around octopuses. First, tell me just how you decided on the octopus as the subject for the second book.
adrian tchaikovsky
So I, much like the spiders, which had been revealed to be really very, very cognitively complex, we’ve kind of always known that octopuses have a lot going on. There are plenty of problem-solving tests and so forth that show that octopuses are very capable of doing a number of complex tasks — getting things out of jars and mazes and so forth.
They have very complex behaviors in the wild that make use of things they wouldn’t necessarily have around if people weren’t around to give them, like coconut halves, for example, which don’t turn up naturally, but which octopuses will quite happily use as a traveling house if they can get hold of them.
And the thing that makes a good subject for this particular series of books is really it’s taking species that have that innate capacity already there and just giving them a little nudge. Because you could take something that the — I don’t want to pick a particular animal because everyone has a favorite animal and I’m bound to offend someone. But you could take a very dull-seeming animal, let’s say in general terms, and say, oh, what would a world be like if this was the dominant species?
But you need a certain kind of evolutionary pressure to get to that point. And I think for that to work, you need something that’s already got a certain amount going on. So octopuses are bright. These jumping spiders are bright. And in another book, I look at corvids, which are notoriously capable animals.
ezra klein
One interesting thing to me about the octopuses is there’s been a real boom in octopus literature over the past couple of years. And that’s been true in non-fiction — really fascinating books exploring the octopus mind and octopus behavior — and then also in fiction. I mean, there’s your book. There’s also the “Mountain in the Sea,” and I think a couple of others.
And part of it seems to me to be motivated by not just that octopuses are smart — although they are, they’re remarkable — but that there’s something very fundamentally alien about them. That really trying to apprehend the way they understand the world and exist in our world is not just as close as we can get right now to meeting aliens, but it basically is like meeting aliens.
And the level of attention we’re able to bring to that or not bring to that actually says a lot about us and our interest in other kinds of minds. How do you think about that alienness?
adrian tchaikovsky
I mean, this is a bit of a bete noire for me, honestly, because we have about 500 million years of fossil evidence for cephalopod evolution. They’re very much not aliens. They are very much our fellow travelers here on Earth, effectively. They are very different to us, though. That’s true.
And one of the things I had to get my head around, because I wanted to write sections from the point of view of an octopus, was the fact that they have a kind of distributed cognition. So that whilst they have a central brain, each arm has its own brain node and the arms do a certain amount of the work of how to do stuff, how to put into action what the octopus wants to happen entirely independent of the brain itself, because physiologically they’re incredibly complicated.
I mean, we as humans have a sense called proprioception, which tells us where the various parts of our body are when we’re not looking at them. So if you put your hand behind your back, you have a sense of where your hand is. As far as we’re aware, octopuses don’t have that.
And they don’t have that because the possible permutations for what an octopus can do to its body is vastly more than anything we can do because we have a limited certain number of joints and a certain amount of degree of freedom for each one. So the octopus’ body, essentially, has to think for itself, which then if you’re trying to write from that perspective and work out what that would be like is really quite mind-wrenching.
ezra klein
There’s also not just what they can do with their body, but what they can do on the canvas of their skin. Can you talk a bit about that?
adrian tchaikovsky
Yes. So octopuses have a variety of chromatophores, so cells in their skin that can generate different pigments. So octopuses are very, very good at camouflage. But they also use their skins, more importantly for the point of view of the book, to signal to one another. And they seem to be signaling emotions as much as anything, that the octopus wants another octopus to know that it is angry, or it is threatening, or it is scared.
And we have video footage of octopuses apparently dreaming so that you would get a shift of patterns on the skin while it’s asleep and things like that. And so the skin seems to be very deeply linked to the octopus’ own thinking. There’s been some weird suggestion that they even have some kind of visual capacity through the skin, although I have to say I’ve not looked — that turned up mostly after I’d written the book and I’ve not looked into that in detail.
But it is a very, very complex organ that is kind of part of their cognition. So the way I treat the octopus mind is that it’s got the arms and it’s got the mind, the central brain, and it has the skin. And all of these three things are equal partners in what the octopus — how the octopus interacts with its environment.
ezra klein
The thing that I found most mind-bending and provocative in that book, it goes to that relationship of the distributed intelligence creating — I think the best way for me to describe it is an emergent quality to thought, right? And then societally, an emergent quality to societal decisions.
We at least like to think — and I agree with you that I don’t really believe it to be true — but we at least like to think there’s a linearity to the way we make decisions. We gather some information. We think about it all, then we come to this final point. And then we like to pretend we do that as a collective, too. We debate, and then people are convinced, and then we end up here or there.
And you’re really playing in that book with this idea of what would it be like if you couldn’t track the causal chain in that same way, that there was this quality of things coming together but not always in full recognition of each other. I’m having trouble knowing how to ask this question because it’s such a weird thing to think about. But how do you imagine that — feeling is maybe the word I’m looking for — how do you think about the difference of that versus at least the folk way we imagine our own thinking to work?
adrian tchaikovsky
I mean, it is a profoundly alien thought. And we are, as a species, at a very basic level, we are very, very committed to the idea that everyone has an I and that I is consistent, and that you can judge a person and that person will act in a certain way. And of course, the more this is studied, the less it appears to be true.
And I kind of accept these days — for example, if you ask me what my favorite this or that is, I will have a different answer every time. And that’s just how things go because myself and my opinion and whatever I dip into at the time. They don’t go everywhere, but they have a cloud of possible ways that I might be thinking depending on what sort of day I’ve had, honestly.
The key thing when describing this for the non-human species for whom it’s an issue, and it’s not even just the octopuses — I think it gets a lot of airing in the third book, in fact — is getting my head around the idea that for them it’s perfectly normal not to have that, and not to want that, and to be able to argue quite cogently that they are not necessarily that kind of individual thinking being.
And really I kind of feel that’s the very heart of science fiction that’s looking at the other is the idea of getting to the point where you can talk about it from the other’s point of view as if all of these profoundly and strange and alien concepts are just basically business as usual by highlighting the alienness of it.
Weirdly enough it detracts from bringing that alienness up to the reader, because the reader can just say, oh, yes, that’s very strange and alien. It’s an alien thing. I don’t really need to understand it. Whereas, if you’re looking at it from the inside of an alien head, or an octopus head in this case, then it’s most profoundly alienating because it’s normal, because it’s not in any way off-putting to the entities that are experiencing it.
[MUSIC]
ezra klein
So the new book, “Children of Memory,” is built, in part, around extremely intelligent corvids, which I was not familiar with the term. So it’s a family of birds. It includes crows and ravens. Tell me what interested you about corvid intelligence.
adrian tchaikovsky
It’s a lot like the octopuses. It’s almost as if they are waiting for their chance. They are incredibly smart. They’re not only able to solve problems and even to make basic tools, they’ve shown the ability to visually appraise a puzzle or a problem, and then solve it straight away, which shows that they are able to envisage stuff and imagine and envisage inside their minds, and work through a series of steps and then just put it into practice straightaway, which is, honestly, something I can’t do most of the time.
If humanity disappeared overnight, and you had this contest, well, who is going to be the next dominant species, I think corvids are very strongly and with a chance. And honestly, if we disappeared overnight and left all our stuff, I think they’d be driving our cars and living in our houses and updating our website within about a few hundred years.
ezra klein
So in the other books, I would say that the uplift virus creates, with some exceptions here, spiders, but much more so in the way they think and operate in the world, and octopuses, but much more so. But you actually make a fascinating change to corvids.
First, you’re imagining intelligence distributed between multiple members of a species. And it felt almost computer-like, like they were operating as a kind of A.I. Tell me a bit about how you changed them, what you built on top of corvid intelligence.
adrian tchaikovsky
So the way the corvid intelligence goes is you have individuals who effectively seek out novelty as we think with magpies and birds and crows and things like that. And then we have the analytical brain that put it all in its place and said, right, that’s not new anymore, we don’t need to look at that, and so forth.
And these are both drawn from behaviors that people have observed in birds. These are things that came up when I was doing my research. Because I knew I wanted to do corvids, but I didn’t know what I wanted to do with them. And so I am still, to a certain extent, building on what we know about crow cognition.
But with the way the corvids develop, I wanted to go in a bit of a different direction rather than relying on the same, oh, well, it’s this virus we’ve had before and this is just what it does to birds. And so I took a very extreme, harsh environment, and thought, all right, how do you survive? What neural specialisms do you need? And how does that arise out of what we’ve got in the basic crow/raven hybrid that they’re working with?
And I can see it as being a computer. And weirdly enough, a lot of people have asked if I was inspired by the ChatGPT-type programs, which is not a thing that were around and being talked about anywhere I could see when I was writing the book.
But what I was also working with was the idea of neurodiversity as a survival trait. It’s something that it’s not often covered in genre fiction. And when it is covered, it’s frequently covered as a background negative. But the idea — this is something that Peter Watts also looks at the benefits of neurodiversity in books like “Blindsight.”
But the idea of actually maybe having that very divergent mental process, maybe that’s actually really useful because being able to see the world in a different way is always going to give you an advantage if you then are able to bring these different worldviews together in a single functioning whole.
ezra klein
I recognize that the timing of the book’s writing can’t really work with ChatGPT, which just came out a couple of months ago. But I do want to talk about it, because one thing that was unbelievably striking — and I guess other people have mentioned this to you — is I feel like this was a single best fictional representation of what it must be like to be a large language model processing system that I’ve read. It was just through crows — or corvids, I should say. They may not have been crows.
And I think to talk about maybe why I found this interesting and to get your thoughts on it, we need to bring in one other piece of how the corvids are portrayed, which is they’re these remarkable problem-solving machines. They’re erudite. You say something to them, they’ll give you back a great quote from literature. But they do not believe they are sentient, and nor at least do some, and particularly the higher order A.I.s of the book — which is a whole other topic — also do not believe they’re sentient.
But the corvids are very consistent and insistent that while they are solving problems, and engaging in conversations, and understanding things at a deep level, and you ask them a question and give you a very relevant answer, that they are like a calculating engine, not a creature with self-reflection and sentience. Tell me about that decision. Why you were trying to write that in and how you thought about it.
adrian tchaikovsky
Well, this very much goes back to what we were talking about a little while ago about the way the human brain works, because, yes, the corvids absolutely insist that they are not in any way sentient. And we, the human-level cognition characters in the book, very much want to feel that they are sentient, because they appear to be sentient, because they act and react in ways that seem to suggest they have an internality and a responsiveness.
And therefore, we conclude, well, you’ll like us. You must be sentient, even though you say you’re not. And the answer the corvids give to that is, well, if you’re like us, then you’re not sentient either. And of course, like we’ve been saying, the human brain does not work in that consistent way. We think and maybe the corvid is right and nobody’s sentient.
And it’s all just — all we think of as us is just this very thin skin of incidental business going on over something that doesn’t have any kind of self-reflection at all. That’s certainly how they would put it. And obviously there are a variety of different levels of cognition and emergent complexity going on in the book that may or may not support their viewpoint.
But that, essentially, they, the corvids, are almost in miniature the central mystery of the book is what is mind, what is alive, what could become something we would consider sentient and how much does that — oh, sorry, sapient. I always say sentient and I always get it wrong — and what does that even mean.
ezra klein
Let me hold for a minute, at least for the purposes of this question, to the idea that the humans are sentient and the corvids are not, and more to the point that we are sentient and ChatGPT or its second and third and fourth and fifth successor programs will not be.
Because one of the things the book is dramatizing, or trying to dramatize, I think, is what would it be like to be a problem-solving machine of remarkable capacity, but to have no idea what the problems are that you’re solving or why you’re saying what you’re saying, which is very much the strangeness of interacting with something like ChatGPT right now.
It can tell you something unbelievably erudite and creative. It can structure it in the form of a poem. And this is true for a number of the other systems. Anthropic has a powerful system. Google and Alphabet have powerful systems. There’s a lot out there now.
I remember one of the Google systems gives a very, very good explanation of a zen koan, but it actually has no idea what it’s saying. And this idea that you could be saying something so sophisticated and so detailed and have no concept of why you’re saying it or what it is you’re saying, it’s very mind-bending. But it’s also, increasingly, I think the world we’re going to be living in. So holding with the idea that maybe we are sentient —
how do you think about that idea that you could have this level of calculating power and relevance — capability to offer relevance in a conversation — but not have any internal life around that conversation?
adrian tchaikovsky
I mean, it’s a weirdly exhilarating and simultaneously terrifying thing that we have got to the point where you can’t do the Turing test anymore. I mean, Eliza, which is something I refer to in the first book — Eliza was an old, a very primitive, effectively automatic psychiatrist program that people could interact with.
And even then, an awful lot of people interacting with this very basic program were convinced it was a person and became quite invested and attached to it, because that is — we are innately predisposed to see things as people. So it’s no wonder there was that case not that long ago of an engineer working with one of these programs who became convinced that it had actually crossed a threshold into genuine sapient.
ezra klein
Right. This is Blake Lemoine, who was working with the Google system.
adrian tchaikovsky
Aha. Yes. And it’s one of those things — you hear it at first — and especially the way it was generally reported on his social media was very much, ha, ha, ha. But the more you think of it, think, well, how would you know? If it did happen, if you cross that invisible threshold and you were dealing with something that had a sense of self, we wouldn’t know. Because we are intentionally creating these systems to interact with us as if they are us.
I mean, this is the weird thing, because, I mean, my weird gut instinct with this sort of thing is, actually, if there is to be a self-aware system somewhere that reaches that level of emergent complexity, it’s probably not going to be this kind of thing. It’s probably going to be something we don’t even think of because we have an awful lot of very, very complex systems.
There’s an idea kicking around back in the ‘80s or ‘90s that maybe the U.S. telephone system was actually complex enough to have surpassed the human brain. And now we’ve got the internet, which is orders of magnitude more complicated.
And you think, is it possible — this may have happened. This may have happened multiple times with brief flares of — it’s a bit like the whale in “Hitchhiker’s Guide,” or this thing suddenly coming to awareness of what am I, what’s going on, what’s that rushing towards me sort of thing.
And I guess the main difference with the chat bot style A.I.s is we are literally training them to fake being us. So you’ve got that combination of this enormous complexity. And it’s self-teaching complexity as well. It’s not — you can’t deconstruct necessarily how it’s got to what it’s doing in the way that you could with older computer systems, because part of the way of creating them is you let them design themselves and expand themselves in a sort of organic way.
I know that there are definitely — there are scientists out there who I’ve heard speak who say that we will never have true strong A.I., an A.I. that has a self and that has a will and that isn’t just going through the motions. If they are wrong, and that strong A.I. is possible, I wouldn’t be remotely surprised if we weren’t on the brink of it, to be honest, purely because of what we’re doing.
And it is that bizarre — the difficulty is because we’re doing it specifically to create systems to interact with us as we interact with ourselves, we’re setting up this system where it becomes impossible to know because we’ve made them — you cannot tell the difference between something that is like us or something that is very, very, very good at pretending to be like us, because that’s what we are training it to do.
ezra klein
And this is why I think that where this ultimately goes with the corvids, this turning around of the question of sentience, is very profound for this moment. And let me not use sentience. Let me use something that is, I think, a little bit simpler to grapple with, which is creativity.
What ChatGPT, what DALL-E-2, and what all the similar programs are able to do in terms of writing text and making images, they are able to make quite remarkable art, or stories, or essays.
And in most cases, it will fall short of the best of what humans can do, but it can also go far beyond what most humans can do.
And we are starting to face, or coming very close to facing this, I think, quite terrible question of what is creativity. If I can train, eventually, a system on Adrian Tchaikovsky novels, and that system can then create — because it can try 10 in a minute — better novels than Adrian Tchaikovsky, in terms of what it is like to read them, does it matter that there was not an intention behind them, aside from I typed in write up some Adrian Tchaikovsky novels, but this time use earthworms as a prompt?
Is what we’re doing just pattern matching as well in a way, right? You can turn — it turns the questions around on us very, very quickly. And so I’m curious how you think of that, because before the systems come for sentience, they’re coming for creativity.
adrian tchaikovsky
Yeah. And I mean, I will absolutely, frankly, say it is a profoundly scary time to be a professional creative at the moment. And I mean, I’m feeling very much that I’m watching people come for the visual artists today and they will be coming for the wordsmiths tomorrow.
So at the moment, it is absolutely true that A.I. can create some very beautiful imagery. At the moment, it is also true that A.I. tends to create very derivative imagery. And there are an awful lot of quite angry artists who feel that they are being kind of robbed, I think possibly quite justifiably, because someone’s taken their back catalog and put it through a machine and then the machine creates almost like a collage in their style.
And it’s called — well, look, here is some new art. And it’s not really. But that doesn’t mean that the next generation, of course, will be able to independently innovate in a way that I think the current generation of A.I. isn’t quite able to do. It depends if they’re the threshold. It depends if there is some sort of hard limit.
I mean, weirdly enough, I’m put in mind of Minecraft, the enormously popular game. Minecraft uses procedurally-generated landscapes. And this is initially absolutely fascinating, because you go, oh, I can go from this biome to that biome, and I can just keep exploring and the world keeps going on. And this is amazing. It’s just this whole world and no one else has ever seen this world. It’s only me and it’s incredible.
And then you realize, well, actually, at the same time, it’s kind of meaningless, because it is just being thrown — it’s being thrown together by an extremely sophisticated algorithm. But basically if you compare it to a world in a game that’s been crafted, there is a difference. And that world — the crafted world — will be a lot smaller, because you can’t just go on forever because obviously every inch of it has taken human work. But at the moment, I think that difference still exists between A.I.-generated and human-generated art because there is that basic meaning that people infuse their work with.
And that you can fake to a point, and it may well be that if we have this conversation next year or in three years time, that point will be passed, and I’ll say, actually, there appears to be genuine meaning — it is drawing levels of meaning and literary reference and awareness of a wider context in this work that goes beyond simply the instructions you’ve given it or beyond the other work that it is being influenced by, because much — all right, I say A.I. is being influenced by other art, but to a certain extent, we all are, and that’s how humans make art by building on art.
So it feels like we’re at a very peculiar fulcrum moment. And I am watching keenly to see how far we tilt, really. How far can this go? Can it go to the point where we’ve gone beyond — well, if you take this style and work out the basic rules of the style, you can keep generating stuff in this style.
ezra klein
I want to take the other side of this conversation just for the sake of it. The size of the island that is human creativity, that is what counts as a creative act, in that telling, it’s worth noting how small it is now. When you say, can A.I. create work that is not derivative? Largely, I agree with you, it can’t.
But most human beings create work that is derivative. And a tremendous amount of certainly the creative economy — and I don’t say this with any sense of judgment. I don’t think there’s anything wrong with this — is work that is derivative.
My son adores the — my four-year-old adores the TV show, “Blaze and the Monster Machines.” I actually think “Blaze and the Monster Machines” is great. Big fan. But episode to episode it’s pretty derivative. But a lot of people are working on that. They’re putting their time into it. But the meaning of it isn’t really the point. And the non-derivativeness isn’t the point.
It’s a common complaint now that we’re endlessly recycling the same IP. There’s nothing we will not turn into a movie from old board games. And we’re remaking all kinds of things. And everything is a sequel on top of a sequel on top of a sequel on top of a sequel. And the secret of it — the thing I think people don’t really want to face up to is people like things with familiarity to it. They like a certain amount of derivativeness in their work.
And so, of course, there’s great art being done that is truly new, truly non-derivative, truly made with meaning as the central intention. But so much of human creation is not about that. And so many of the people who are creators, that is not what they are doing. And it is not what they have been asked to do. And to some degree, if you’ve got to beat the A.I.s that are going to come in five years, it may not be what most of us can do. I mean, there may always be a space for the very best.
But I find it really much more frightening than I think people want to give it credit for if you say that the A.I. will be able to do anything so long as it is somewhat derivative of everything that has come up until this point, or so long as meaning — a really deep structure of meaning is not central to the project. Because just how many things that we make really do satisfy the meaning is central and this is non-derivative conditions? I think it’s pretty small.
adrian tchaikovsky
Yeah, and I have no answer. I think everything you said is pretty much bang on the money. There was a rather depressing cartoon that might have been in the British magazine “Private Eye” of how we thought the future would be, which is a human painting a picture, and in the background, the robot is doing the vacuuming. And then how the future is going to be, which is the robot painting the picture and the human doing the vacuuming because —
ezra klein
That’s very good.
adrian tchaikovsky
Yeah. There’s going to be a lot of those — physical tasks will probably still be more economical to be done by humans. But if an A.I. can produce 1,000 novels and two million paintings in 20 minutes, then even if a lot of them aren’t any good, that’s still going to be very, very commercially viable.
[MUSIC]
ezra klein
There is a sci-fi story that always sticks in my mind here, and I apologize because I don’t know its name and I don’t know the author. And maybe you will. I’m sure somebody listening will. But I think it is structured — I read it as a child. And I think it’s structured the way I think about all of this. It’s a story about the widow of a musician going in to meet a senator. And what has happened is that the senator has supported — it’s a short story — the senator has supported a basically — I don’t remember if it’s infinite or lifetime — it’s a very, very long extension of copyright.
And this is happening in a world where automation and artificial intelligence have basically made it so that most human beings are artists. That is what they put on their job description. I’m an artist. And the protagonist of the story, the widow, had tried to buy off the senator to get him to kill this bill. But he didn’t, at least at that point in the story.
And she comes in and is like, why are you doing this? And he says, I don’t really understand why you don’t want this. I mean your husband was this famed composer. You’re going to make all this money. This is great for you. What’s the problem here? And she basically says, my husband killed himself when he realized that this song he had made for me had already been made.
And she said that the amount of art there is may be large, but it is not infinite. And if we force society to remember, and if we force people to confront the fact that they are becoming derivative, that they can’t keep making new things, that they’re not making new things, it will be a psychic trauma of such size that we will not be able to deal with it. And the end of the story is he kind of flips and kills the bill.
But it’s always struck me. For some reason, it’s really burrowed very deep in me this idea that it would be very devastating to the human spirit if we come to believe that we are just derivative, if we come to believe that we have exhausted the possibilities for our own creativity.
And I’m not saying we’re on the waterline of that, but I’m also not exactly saying we’re not. I’m curious, one, if you remember that story, if that rings any bells for you, but also how you think about that — the psychic dimension of this.
adrian tchaikovsky
I mean, that’s not one I’ve come across. As far as the theme goes, I mean, I would like to say — and this is possibly just me standing up for my — the creative professions — that the universe has a number of things, which, whilst theoretically limited, will have enough variety in them to outlast any reasonable time period you might have to work through them.
And it would be nice to think that human creativity is one of those, but possibly that’s just me doing a bit of special pleading.
It also raises the dreadful specter of someone being sued by an A.I. program for copying their stuff, which is —
ezra klein
That’s a good topic for a short story.
adrian tchaikovsky
Well, I mean the legal ramifications of A.I. art are currently going under the microscope in courts, I believe, especially with where they are very obviously and intentionally drawn from particular artists over it. But that’s another discussion entirely.
I’m not sure it would come to that, purely because from what — based on something you were saying earlier, which is the idea that actually a lot of the time we are retreading. I mean, I build my writing on the backs of all the people I have read.
And some of the time I will read something and think I really enjoyed that, here is a slightly different way that I would do that. And it’s enough of a different spin to send me off and produce quite a different book just from wanting to tackle a situation or a concept that I’ve seen in a different way. I think you can tread very finely on someone’s heels in that ideas more for space and still be sufficiently different.
You were talking about the cartoon your son likes. I’m put in mind of my son used to watch “Power Rangers” for a while. And all of these episodes are kind of the same. They have exactly the same structure. The villain is different. And that’s kind of the thing that happens is this time we’re fighting this villain, and then we’ll have the same five beats to the story. And this is like, there are how many “Power Rangers” episodes?
So I think you can slice that creativity extremely finely and still produce stuff that works for the people who like that particular thing. So hopefully we’ll never get to that point where you run out of all the — there are no more songs and there are no more stories because every possible iteration of them has been told.
ezra klein
So one way a lot of sci-fi has dealt with this problem is to say that if you relax the constraint on what we might call scarcity-driven purposefulness — it’s not quite just capitalism because you have this in other societies, too — but if you relax the idea that the worth of a human life is measured to say nothing of their ability to get housing and shelter and so on, in terms of what they offer to society, what they produce, then a lot of these problems simply dissolve.
Because, yeah, look, A.I.s can create a million paintings and stories, and they can run our companies eventually and all of it. And what they can’t do is experience a day at the park for us. What they can’t do is take a walk in the woods with their children for us. And maybe they can, but it won’t have the same meaning.
And that it’s only this obsessive emphasis we place, as a species borne out of scarcity that’s been clawing our way up out of endless exposure to nature and viruses and weather and all the rest of it, that it’s really just getting past that and the idea of a world where I can do everything or a lot of things.
And the question of how much utility we have just goes away, because the point is it would be nice to just paint. And to the point of that cartoon you mentioned a minute ago, the idea that the A.I. will be painting and we will not be, I mean, I do a lot of things that professionals do better than me. But I don’t not do them because somebody is out there making money from it. I would like to say painting is one of them, but I really don’t paint.
But when I make music — I play the guitar a little bit — the fact that people are out there being paid to be great guitar players has nothing to do — it exists in a wholly different universe than my enjoyment of playing the guitar. And so maybe this is all just the entire tension here is just our social expectations. But you get rid of them and there’s no problem at all. Do you buy that strain of sci-fi solution to this problem?
adrian tchaikovsky
I think there’s a lot to that. I mean, there are things I do that I do because they are de-stressing activities. I also write a lot as anyone who knows my books will attest to.
ezra klein
It’s genuinely astonishing how many books you write.
adrian tchaikovsky
And that’s a big part of my self-image. And one of the things I have never ever purely written for me. And I appreciate writing for an audience and writing for a commercially supportive career are two different things. But they’re kind of two different stations on a longer spectrum I think.
I think one of the reasons that kind of Minecraft paradigm exists, the weird the emptiness of that Minecraft universe is that there’s no one looking back at you. You don’t get that dialogue between creator and created, and creator and viewer, consumer, I guess, which is a major part of how art works. It’s not just in the creation of art. It’s in the way people come to it and the effect it has on them.
And the idea — as a creator, I’m writing things I want people to enjoy and I want people to think about. And if that wasn’t there — if basically I was just given the wherewithal, yes, you can write all you want, write every story you ever wanted to get out, and we’ll put it in this box and that’s where it will stay, but you’ll have written them, I probably wouldn’t write.
And weirdly, I mean, constraints are useful. I mean, the number of people you meet who say, well, when I retire, I’m going to do this, I’m going to do that. And then they retire and they don’t because the pressure is off. And that’s another factor.
The counter-argument being, of course, that an awful lot of people have so much — are so constrained by the lives that they have that all of the creativity that they could give to the world just never had the chance to get out because creativity takes time. Creativity, historically, has often been something that rich people to get about and do because they have the time and their needs are already met.
So I guess what all this meandering is taking us to is it’s complicated. I think that meeting people’s basic needs so that if they would like to be able to just create, that they can do, I think that’s got to be considered a basic good. But I think the act of creation is a very complex dialogue with how human society works as well.
ezra klein
This, I think, circles us back actually to humans and to your books, because to get at something you mentioned there, it’s really interesting, we have these studies of people who are unemployed, and then while they are long-term unemployed, they shift into an age group where they become retired.
That becomes their self-definition and it really changes their mental status. They’re happier. Just moving from being unemployed to retired, though those are similar statuses in many ways because of how we treat ourselves and how others treat us, it really changes the experience people have of their own life.
And one thing I found very moving — and this does speak to something important in “Children of Time,” but I don’t think it ruins the experience of the book at all, is that when the virus gets turned on humans, what really gets upgraded, as best I understand it, is not our intelligence. We’re not made super smart. But we’re made much more empathic. We’re made much more capable of recognizing ourselves in the other and treating the other as we would want to be treated.
And I found that a quite interesting way of thinking about the deficiency of human beings. Tell me a bit about how you understood that device and that decision.
adrian tchaikovsky
So I mean, just for a little bit of background, this is the solution to the sociability problem in that if you have this virus, you recognize it in others. And that means that you see those others as people in a way that if you were a spider, you might not see another spider as people insofar as spiders ever do because that other spider might also be lunch.
But also, it means that when the humans are brought into the equation, the humans are able to perceive the spiders as us rather than them. And humanity is a species that is weirdly strung between these two poles of our social bonds with our fellow humans, whether it’s family group, or colleagues, or whatever — we’re extremely good at making small groups within the larger group that we then belong to very fervently, whether you’re supporting a sports team or a political party or that kind of thing. And we become incredibly tribal about it.
And the other side of that equation is we emphasize the us and the thing we belong to by making a them. And that becomes inordinately problematic. And because we have a lot of social structures that essentially profit very strongly from having a them that we can dehumanize, the idea of having this virus, which would essentially forcibly humanize or rehumanize the other so that you can’t just write them off as them.
I mean, one of the things that genre fiction is very fond of is a them to whom you can do terrible things to, whether it’s robots, or zombies, or orcs, or spiders, for that matter, a giant — “Starship Troopers,” it’s the bugs in — giant insects or whatever. It’s that thing that you can say, well, it doesn’t matter how many of these things we kill or whether we can exterminate them out of the face of the universe because they were them. They were not really — they were not people. They were just this unthinking force that it’s absolutely right and proper to get rid of. And that’s a big genre trope that I’ve always had a problem with. And so the introduction of the virus to humans in “Children of Time,” it breaks that down, so you can’t turn something else into them in the same way.
ezra klein
One of the things that then opens up, particularly in “Children of Memory” and “Children of Time,” is this question of once you want to have this kind of communication, because you see very, very different kinds of creatures as part of your community, how do you do it? And these are books very centrally concerned with communication.
So first, just tell me a bit about why that has been so central in your work. It’s also central in your ongoing — “The Architect” series, where you have these giant planetary alien-level somethings that are remaking our world into art. And the question of how do you communicate is very central. Tell me about your focus on this question of, can we make ourselves understood to one another?
adrian tchaikovsky
I mean, something that runs through an awful lot of my work — and obviously, I mean, I am very heavily invested in — I mean, the animal kingdom, in general, turns up in various of my books in various forms and the idea of — you’ve got that old idea of, well, if a lion could speak, we couldn’t understand it, which is simultaneously very true and something I’ve never been particularly happy with.
So I’m constantly Rube Goldberg-ing my lion communication devices through various different books and working out various different ways that you can bridge that gap between very, very different minds of different cognitive structures — aliens, and uplifted animals, and hyper-evolved trilobites in one of the books, and all of these different things. And just where would you find the common ground? And where would you — how would you actually start to speak to something that was profoundly different to us?
And at some point, this may — I mean, it would be lovely to think it would be in my lifetime, although it seems rather unlikely. At some point, this is going to be something humans will probably have to deal with. We’re looking at exoplanets. A lot of them seem to be potentially life-supporting. And that’s just looking at life as we understand it. And there might be a lot of life out there that’s profoundly different to us in ways that are — the province of molecular chemistry as much as biology or psychology.
But if we meet it, and if it has a sentience anywhere near ours or any kind of sentient sapient at all, we would have a duty to try and communicate, to try and bridge that gap. And so I run through these thought experiments really looking at what we know of even Earth creatures that are very different to us in the way that they operate, and thinking, well, where do you come together?
ezra klein
This theme of your books had a similar quality to the question of sentience for me, where it seemed to turn the telescope around a bit. When I think of a movie like “Arrival,” which is all about the question of how would we learn to communicate with a highly advanced alien civilization that landed here, in some way if we’ve decided the communication needs to happen and we know it has to happen with something very, very different from us, at least we know what the problem is that has to be solved. Maybe it’s not solvable, but at least we, I think, assess it correctly.
And something that struck me, thinking about these questions within the context of your books, is how often we are deceived, I think, by thinking it’s not a problem at all within our own species. How much within a marriage, within a friendship, within a family, between countries, between different groups of people, the assumption is we can communicate. The assumption is you’re hearing what I have said and you are just not doing it, or you know what it is I need and you’re just not providing it. You are like me, and then by acting in a way that I don’t like, you are rejecting me.
How much we think communication should be a solved problem and it isn’t, and how much of conflict and enmity and resentment and hurt I think comes from a real underestimation of just how different even someone who lives with us, and knows us, and loves us, is from us, how different their experience of the world is. And I don’t know how rarely we’re really taught to appreciate the difficulty of communicating, even comparatively to your books, minor gap that separates us from each other.
adrian tchaikovsky
I think that’s very true. I think empathy is a great human ability, but it is something we are, I think, constantly in danger of losing because we do construct pictures of the people we interact with in our heads based on the signals they are sending out and completely ignorant of the internality of what’s going on. So that the driver in front of you is very slow, so you’re very annoyed. And you construct this idea of, well, obviously they’re just doing this to annoy me, or they’re a bad driver, or something. You don’t know what day they’ve had and what problems they’ve got.
And certainly, I can go home and someone will say something to me and I will be annoyed. And I will think, well, they’re being very annoying today. They’re obviously just trying to get a rise out of me or something like that. And actually, no, it’s because I’ve had a bad day. And they’ve said something entirely incongruous.
But I mean, this comes back also to our sense of a fixed self and the fact that it is not the case. Rather than interpret events say, well, I am obviously out of sorts today, it’s much more of a knee-jerk human reaction to say, well, that person is deliberately being aggravating, that person is — they’re being slow. They’re not understanding — it’s not that I haven’t said something cogently, it’s that they are willfully not understanding what I’m saying.
And again, I think it really does come back to this idea that we believe ourselves to be the unconquerable self, this concrete unchanging, this is the way we are-ness of us, which doesn’t really exist. But rather than confront the fact that it doesn’t exist, we externalize the fault of any miscommunications and problems with our social interactions with others onto those others. And of course, because they’re also doing it to us, this is where arguments come from.
ezra klein
I think that is a lovely place to end. So always our final question, what are three books that have influenced you that you would recommend to the audience?
adrian tchaikovsky
So Gene Wolfe’s “Soldier of the Mist” is a fascinating exploration of a book written by someone who doesn’t have that core of self, because it’s the diary of an amnesiac soldier, in fact, back in Hellenic, Greece, whose account of battles and gods and monsters and all manner of stuff is just told day to day by someone who cannot remember what they wrote down previously, and very seldom had the chance to read up on their own notes.
“After Atlas” by Emma Newman is one I’d throw out there. That’s a relatively recent science fiction book in her “Planet Fall” series. And I throw it in there mostly because it has some of the most bleakly plausible bad human politics going on there.
I mean, I tend to like to talk about recent books rather than the classic golden age of science fiction because I feel we’ve got a lot of very interesting stuff going on with this genre right now.
Another recent book is R.F. Kuang’s “Babel,” which has the most astonishing examination of imperialism and language and appropriation as part of its fantasy plot.
ezra klein
Adrian Tchaikovsky, thank you very much.
adrian tchaikovsky
Thank you. [MUSIC]
“The Ezra Klein Show” is produced by Emefa Agawu, Annie Galvin, Jeff Geld, Rogé Karma and Kristin Lin. Fact-checking by Michelle Harris. Mixing by Sonia Herrero. Original music by Isaac Jones. Audience strategy by Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. Special thanks to Carole Sabouraud and Kristina Samulewski.
Listen
 1:05:00 
[MUSIC]
EZRA KLEIN: I’m Ezra Klein. This is “The Ezra Klein Show.”
So a while back I did an episode on octopuses and I immediately got all these emails from you saying, have you read Adrian Tchaikovsky’s “Children of Ruin?” “Children of Ruin,” when I looked it up, turns out to be a sci-fi book about an advanced civilization built by octopuses, which sold — completely sold immediately on that.
And so I bought it and I started reading it. And then I realized you had to first read the other book in the series, “Children of Time,” which is an advanced civilization built by spiders. And that’s, of course, the second best description of any book I’ve ever read after the octopus one. So I stopped where I was, I got that, and I never looked back.
And I loved these books. They really work through this question of what a civilization built by a very different kind of creature that has a very different sensorium would look like. These books leave you, as the human being reading them, very much feeling like the other, feeling like the one whose mind and hands and society are the clumsy imitation. It’s just a wonderful act of self-alienation.
And for about a year after I read them, every time I would read a normal fiction book about some creative types living in New York, struggling with their creative type problems, I would just have this thought running through my head. I mean, that’s all interesting, but it’s not advanced civilization built around spiders-level interesting. But that didn’t exactly lend itself to a show.
And then Tchaikovsky brought out his new book, “Children of Memory.” And this one is about corvids, about a kind of bird, or at least that’s what it is supposed to be about. But I wasn’t alone in finding it to be an almost astonishingly good book about A.I. It came out right about the time ChatGPT was blowing up.
And “Children of Memory,” whether it was intended or not, it is the single best piece of fiction I’ve read on what it is like — the confusion, the disorientation of interacting with a problem-solving erudite, brilliant, trained to some degree on humans, but not necessarily sanctioned A.I., and also, to the extent this sentence makes any sense, what it might be like to be one.
Editors’ Picks
A Movie Confronts Germany’s Other Genocide
Gego: Drawing in Space at the Guggenheim
Millennials Pay for a Dose of ’90s Nostalgia
Continue reading the main story
What Tchaikovsky is remarkable at doing across all these books is imagining how other kinds of minds and other kinds of ways of experiencing the world lead to other worlds, and then thinking about what finding those worlds would do to human beings and the way we experience our world and ourselves.
And so this conversation is about that. We talk a bit about spiders and octopuses and corvids, because I don’t think we should forget that even before A.I., we inhabited and inhabit a world with many remarkable minds, very unlike our own. But the core of this conversation is about A.I., and particularly what it will mean for humanity’s sense of our minds, of our capacities, of what makes us us.
Last thing, I talk a bit about a sci-fi story in here that I could not remember the name of. Our amazing fact-checker, Michelle Harris, found it. It is “Melancholy Elephants” by Spider Robinson. And we will put a link to that in Show Notes. As always, if you’ve got any suggestions, guest ideas, feedback to send us, ezrakleinshow@nytimes.com.
[MUSIC]
Adrian Tchaikovsky, welcome to the show.
ADRIAN TCHAIKOVSKY: Hello. Thank you very much.
EZRA KLEIN: So the first book in your “Children of Time” series centers around a planet where an advanced civilization was built by spiders. Why spiders?
ADRIAN TCHAIKOVSKY: The book is about empathy and is about empathy for the other — that is the main theme of the series as a whole. And there’s nothing in the world that people hate more than spiders. If you go on social media with a post about spiders, someone will respond saying, you now have to burn the house down. And so if you can make people empathize with spiders, you can make people empathize for anything.
EZRA KLEIN: But I’ve heard you say that you begin in all of these books trying to understand the sensorium of the animal or the insect under consideration. So tell me how would you describe the way a spider senses the world.
ADRIAN TCHAIKOVSKY: So the Portia spiders, which I’m using, are very, very visual creatures, and they have that in common with us. So they are very sight-based, very motion-based. But at the same time, spiders have an enormously well-developed sense of vibration.
So the way these spiders communicate, a lot of it is through visual signaling and it’s through a vibrational sense. So they dance, which is something that spiders do for various purposes in the real world, but they dance to communicate and the patterns of vibration allow them to speak to one another.
And at the same time, they have a very highly developed chemical sense. So the spider — the ability to taste through the various sensory organs and hairs and so forth is very acute. And that then becomes a base of their technology. So they have this ability to do a scientific alchemy just freehand.
And of course, with web-spinning, that gives them a technological advantage that a lot of creatures wouldn’t have. And that they can create containers and tools and simple machines, even just with the stuff that comes out of their bodies.
EZRA KLEIN: Tell me about how you solve the problem of language, and particularly language that can reach many spiders or inhabitants of the city at once in the book.
ADRIAN TCHAIKOVSKY: So they have a simple visual language, which can reach over distances. But, yes, the problem with your vibrational language is it’s obviously rather limited. And of course, it’s a problem that spiders have already solved, because that’s what your web is for. Your spider web is not just for catching prey. It is a kind of an extended sensory organ to send and receive signals.
And so if you get a bunch of spiders on a web, you can speak to the crowd from the center of the web. And then individuals can send signals back to you. And with a sort of finesse of a creature that’s had a long time to evolve this practice, you could have, effectively, multiple conversations going on down different strands, just as you would have the crowd of people talking in a bar, for example.
EZRA KLEIN: I lived in a home in Oakland for a couple of years that was absolutely entombed in spiders and spider webs.
Not in a normal way. I mean, we would have conversations with friends that was — do you have spiders in the back? Yeah, we get some spiders. I mean, but like everywhere, like your whole thing is covered in webs? And you would — if anything happened that got rid of the webs, like a rain, they’d be back the next day.
And their just complexity and the speed with which they could create them was a complete marvel to me. And I think it also speaks a little bit to why people are unusually afraid of spiders. There’s something very otherworldly about the spider web and that act of creation and trapping.
So tell me a little bit more about webs. When you did this research, there’s what the spiders can do and then there’s what they build, because they are building species in this very intense way. How do you understand the relationship to webs?
ADRIAN TCHAIKOVSKY: There’s been research, certainly since I wrote the book, that’s exploring the full complexity of the spider web. And the idea that the web is something that spiders actually use to export part of their cognitive load in the same way that I use my — my phone is basically where I keep most of my memory of what I’m supposed to be doing at any time.
A spider’s web is doing a lot of the thinking for the spider in the way it constructs it and in the way the vibrations move along it. So that they’re almost bootstrapping their own intelligence because of what they can build.
And in the book, the webs become very much not just the focus of how they construct their technology — so they develop, effectively, a very advanced society without ever really getting to grips with things like fire or the wheel. So a lot of human mainstays they don’t have. But they also they don’t need because they work through a far more of a chemical synthesis and biotech solution because of their own peculiar sensory abilities and their own physical capacity.
But the web also informs the way that they interact with each other in the world. So they — to the spiders in the book, the idea of being connected to anything, to everything, the idea of everything influencing everything else is far more prevalent. So they have less of a bullish attitude towards the world than, historically, humans have often had, and therefore, more to do with, well, how can we make things fit in and work as part of our systems.
EZRA KLEIN: So the second book in the series is “Children of Ruin.” One of the main things it’s about is a society that built up around octopuses. First, tell me just how you decided on the octopus as the subject for the second book.
ADRIAN TCHAIKOVSKY: So I, much like the spiders, which had been revealed to be really very, very cognitively complex, we’ve kind of always known that octopuses have a lot going on. There are plenty of problem-solving tests and so forth that show that octopuses are very capable of doing a number of complex tasks — getting things out of jars and mazes and so forth.
They have very complex behaviors in the wild that make use of things they wouldn’t necessarily have around if people weren’t around to give them, like coconut halves, for example, which don’t turn up naturally, but which octopuses will quite happily use as a traveling house if they can get hold of them.
And the thing that makes a good subject for this particular series of books is really it’s taking species that have that innate capacity already there and just giving them a little nudge. Because you could take something that the — I don’t want to pick a particular animal because everyone has a favorite animal and I’m bound to offend someone. But you could take a very dull-seeming animal, let’s say in general terms, and say, oh, what would a world be like if this was the dominant species?
But you need a certain kind of evolutionary pressure to get to that point. And I think for that to work, you need something that’s already got a certain amount going on. So octopuses are bright. These jumping spiders are bright. And in another book, I look at corvids, which are notoriously capable animals.
EZRA KLEIN: One interesting thing to me about the octopuses is there’s been a real boom in octopus literature over the past couple of years. And that’s been true in non-fiction — really fascinating books exploring the octopus mind and octopus behavior — and then also in fiction. I mean, there’s your book. There’s also the “Mountain in the Sea,” and I think a couple of others.
And part of it seems to me to be motivated by not just that octopuses are smart — although they are, they’re remarkable — but that there’s something very fundamentally alien about them. That really trying to apprehend the way they understand the world and exist in our world is not just as close as we can get right now to meeting aliens, but it basically is like meeting aliens.
And the level of attention we’re able to bring to that or not bring to that actually says a lot about us and our interest in other kinds of minds. How do you think about that alienness?
ADRIAN TCHAIKOVSKY: I mean, this is a bit of a bete noire for me, honestly, because we have about 500 million years of fossil evidence for cephalopod evolution. They’re very much not aliens. They are very much our fellow travelers here on Earth, effectively. They are very different to us, though. That’s true.
And one of the things I had to get my head around, because I wanted to write sections from the point of view of an octopus, was the fact that they have a kind of distributed cognition. So that whilst they have a central brain, each arm has its own brain node and the arms do a certain amount of the work of how to do stuff, how to put into action what the octopus wants to happen entirely independent of the brain itself, because physiologically they’re incredibly complicated.
I mean, we as humans have a sense called proprioception, which tells us where the various parts of our body are when we’re not looking at them. So if you put your hand behind your back, you have a sense of where your hand is. As far as we’re aware, octopuses don’t have that.
And they don’t have that because the possible permutations for what an octopus can do to its body is vastly more than anything we can do because we have a limited certain number of joints and a certain amount of degree of freedom for each one. So the octopus’ body, essentially, has to think for itself, which then if you’re trying to write from that perspective and work out what that would be like is really quite mind-wrenching.
EZRA KLEIN: There’s also not just what they can do with their body, but what they can do on the canvas of their skin. Can you talk a bit about that?
ADRIAN TCHAIKOVSKY: Yes. So octopuses have a variety of chromatophores, so cells in their skin that can generate different pigments. So octopuses are very, very good at camouflage. But they also use their skins, more importantly for the point of view of the book, to signal to one another. And they seem to be signaling emotions as much as anything, that the octopus wants another octopus to know that it is angry, or it is threatening, or it is scared.
And we have video footage of octopuses apparently dreaming so that you would get a shift of patterns on the skin while it’s asleep and things like that. And so the skin seems to be very deeply linked to the octopus’ own thinking. There’s been some weird suggestion that they even have some kind of visual capacity through the skin, although I have to say I’ve not looked — that turned up mostly after I’d written the book and I’ve not looked into that in detail.
But it is a very, very complex organ that is kind of part of their cognition. So the way I treat the octopus mind is that it’s got the arms and it’s got the mind, the central brain, and it has the skin. And all of these three things are equal partners in what the octopus — how the octopus interacts with its environment.
EZRA KLEIN: The thing that I found most mind-bending and provocative in that book, it goes to that relationship of the distributed intelligence creating — I think the best way for me to describe it is an emergent quality to thought, right? And then societally, an emergent quality to societal decisions.
We at least like to think — and I agree with you that I don’t really believe it to be true — but we at least like to think there’s a linearity to the way we make decisions. We gather some information. We think about it all, then we come to this final point. And then we like to pretend we do that as a collective, too. We debate, and then people are convinced, and then we end up here or there.
And you’re really playing in that book with this idea of what would it be like if you couldn’t track the causal chain in that same way, that there was this quality of things coming together but not always in full recognition of each other. I’m having trouble knowing how to ask this question because it’s such a weird thing to think about. But how do you imagine that — feeling is maybe the word I’m looking for — how do you think about the difference of that versus at least the folk way we imagine our own thinking to work?
ADRIAN TCHAIKOVSKY: I mean, it is a profoundly alien thought. And we are, as a species, at a very basic level, we are very, very committed to the idea that everyone has an I and that I is consistent, and that you can judge a person and that person will act in a certain way. And of course, the more this is studied, the less it appears to be true.
And I kind of accept these days — for example, if you ask me what my favorite this or that is, I will have a different answer every time. And that’s just how things go because myself and my opinion and whatever I dip into at the time. They don’t go everywhere, but they have a cloud of possible ways that I might be thinking depending on what sort of day I’ve had, honestly.
The key thing when describing this for the non-human species for whom it’s an issue, and it’s not even just the octopuses — I think it gets a lot of airing in the third book, in fact — is getting my head around the idea that for them it’s perfectly normal not to have that, and not to want that, and to be able to argue quite cogently that they are not necessarily that kind of individual thinking being.
And really I kind of feel that’s the very heart of science fiction that’s looking at the other is the idea of getting to the point where you can talk about it from the other’s point of view as if all of these profoundly and strange and alien concepts are just basically business as usual by highlighting the alienness of it.
Weirdly enough it detracts from bringing that alienness up to the reader, because the reader can just say, oh, yes, that’s very strange and alien. It’s an alien thing. I don’t really need to understand it. Whereas, if you’re looking at it from the inside of an alien head, or an octopus head in this case, then it’s most profoundly alienating because it’s normal, because it’s not in any way off-putting to the entities that are experiencing it.
[MUSIC]
EZRA KLEIN: So the new book, “Children of Memory,” is built, in part, around extremely intelligent corvids, which I was not familiar with the term. So it’s a family of birds. It includes crows and ravens. Tell me what interested you about corvid intelligence.
ADRIAN TCHAIKOVSKY: It’s a lot like the octopuses. It’s almost as if they are waiting for their chance. They are incredibly smart. They’re not only able to solve problems and even to make basic tools, they’ve shown the ability to visually appraise a puzzle or a problem, and then solve it straight away, which shows that they are able to envisage stuff and imagine and envisage inside their minds, and work through a series of steps and then just put it into practice straightaway, which is, honestly, something I can’t do most of the time.
If humanity disappeared overnight, and you had this contest, well, who is going to be the next dominant species, I think corvids are very strongly and with a chance. And honestly, if we disappeared overnight and left all our stuff, I think they’d be driving our cars and living in our houses and updating our website within about a few hundred years.
EZRA KLEIN: So in the other books, I would say that the uplift virus creates, with some exceptions here, spiders, but much more so in the way they think and operate in the world, and octopuses, but much more so. But you actually make a fascinating change to corvids.
First, you’re imagining intelligence distributed between multiple members of a species. And it felt almost computer-like, like they were operating as a kind of A.I. Tell me a bit about how you changed them, what you built on top of corvid intelligence.
ADRIAN TCHAIKOVSKY: So the way the corvid intelligence goes is you have individuals who effectively seek out novelty as we think with magpies and birds and crows and things like that. And then we have the analytical brain that put it all in its place and said, right, that’s not new anymore, we don’t need to look at that, and so forth.
And these are both drawn from behaviors that people have observed in birds. These are things that came up when I was doing my research. Because I knew I wanted to do corvids, but I didn’t know what I wanted to do with them. And so I am still, to a certain extent, building on what we know about crow cognition.
But with the way the corvids develop, I wanted to go in a bit of a different direction rather than relying on the same, oh, well, it’s this virus we’ve had before and this is just what it does to birds. And so I took a very extreme, harsh environment, and thought, all right, how do you survive? What neural specialisms do you need? And how does that arise out of what we’ve got in the basic crow/raven hybrid that they’re working with?
And I can see it as being a computer. And weirdly enough, a lot of people have asked if I was inspired by the ChatGPT-type programs, which is not a thing that were around and being talked about anywhere I could see when I was writing the book.
But what I was also working with was the idea of neurodiversity as a survival trait. It’s something that it’s not often covered in genre fiction. And when it is covered, it’s frequently covered as a background negative. But the idea — this is something that Peter Watts also looks at the benefits of neurodiversity in books like “Blindsight.”
But the idea of actually maybe having that very divergent mental process, maybe that’s actually really useful because being able to see the world in a different way is always going to give you an advantage if you then are able to bring these different worldviews together in a single functioning whole.
EZRA KLEIN: I recognize that the timing of the book’s writing can’t really work with ChatGPT, which just came out a couple of months ago. But I do want to talk about it, because one thing that was unbelievably striking — and I guess other people have mentioned this to you — is I feel like this was a single best fictional representation of what it must be like to be a large language model processing system that I’ve read. It was just through crows — or corvids, I should say. They may not have been crows.
And I think to talk about maybe why I found this interesting and to get your thoughts on it, we need to bring in one other piece of how the corvids are portrayed, which is they’re these remarkable problem-solving machines. They’re erudite. You say something to them, they’ll give you back a great quote from literature. But they do not believe they are sentient, and nor at least do some, and particularly the higher order A.I.s of the book — which is a whole other topic — also do not believe they’re sentient.
But the corvids are very consistent and insistent that while they are solving problems, and engaging in conversations, and understanding things at a deep level, and you ask them a question and give you a very relevant answer, that they are like a calculating engine, not a creature with self-reflection and sentience. Tell me about that decision. Why you were trying to write that in and how you thought about it.
ADRIAN TCHAIKOVSKY: Well, this very much goes back to what we were talking about a little while ago about the way the human brain works, because, yes, the corvids absolutely insist that they are not in any way sentient. And we, the human-level cognition characters in the book, very much want to feel that they are sentient, because they appear to be sentient, because they act and react in ways that seem to suggest they have an internality and a responsiveness.
And therefore, we conclude, well, you’ll like us. You must be sentient, even though you say you’re not. And the answer the corvids give to that is, well, if you’re like us, then you’re not sentient either. And of course, like we’ve been saying, the human brain does not work in that consistent way. We think and maybe the corvid is right and nobody’s sentient.
And it’s all just — all we think of as us is just this very thin skin of incidental business going on over something that doesn’t have any kind of self-reflection at all. That’s certainly how they would put it. And obviously there are a variety of different levels of cognition and emergent complexity going on in the book that may or may not support their viewpoint.
But that, essentially, they, the corvids, are almost in miniature the central mystery of the book is what is mind, what is alive, what could become something we would consider sentient and how much does that — oh, sorry, sapient. I always say sentient and I always get it wrong — and what does that even mean.
EZRA KLEIN: Let me hold for a minute, at least for the purposes of this question, to the idea that the humans are sentient and the corvids are not, and more to the point that we are sentient and ChatGPT or its second and third and fourth and fifth successor programs will not be.
Because one of the things the book is dramatizing, or trying to dramatize, I think, is what would it be like to be a problem-solving machine of remarkable capacity, but to have no idea what the problems are that you’re solving or why you’re saying what you’re saying, which is very much the strangeness of interacting with something like ChatGPT right now.
It can tell you something unbelievably erudite and creative. It can structure it in the form of a poem. And this is true for a number of the other systems. Anthropic has a powerful system. Google and Alphabet have powerful systems. There’s a lot out there now.
I remember one of the Google systems gives a very, very good explanation of a zen koan, but it actually has no idea what it’s saying. And this idea that you could be saying something so sophisticated and so detailed and have no concept of why you’re saying it or what it is you’re saying, it’s very mind-bending. But it’s also, increasingly, I think the world we’re going to be living in. So holding with the idea that maybe we are sentient —
how do you think about that idea that you could have this level of calculating power and relevance — capability to offer relevance in a conversation — but not have any internal life around that conversation?
ADRIAN TCHAIKOVSKY: I mean, it’s a weirdly exhilarating and simultaneously terrifying thing that we have got to the point where you can’t do the Turing test anymore. I mean, Eliza, which is something I refer to in the first book — Eliza was an old, a very primitive, effectively automatic psychiatrist program that people could interact with.
And even then, an awful lot of people interacting with this very basic program were convinced it was a person and became quite invested and attached to it, because that is — we are innately predisposed to see things as people. So it’s no wonder there was that case not that long ago of an engineer working with one of these programs who became convinced that it had actually crossed a threshold into genuine sapient.
EZRA KLEIN: Right. This is Blake Lemoine, who was working with the Google system.
ADRIAN TCHAIKOVSKY: Aha. Yes. And it’s one of those things — you hear it at first — and especially the way it was generally reported on his social media was very much, ha, ha, ha. But the more you think of it, think, well, how would you know? If it did happen, if you cross that invisible threshold and you were dealing with something that had a sense of self, we wouldn’t know. Because we are intentionally creating these systems to interact with us as if they are us.
I mean, this is the weird thing, because, I mean, my weird gut instinct with this sort of thing is, actually, if there is to be a self-aware system somewhere that reaches that level of emergent complexity, it’s probably not going to be this kind of thing. It’s probably going to be something we don’t even think of because we have an awful lot of very, very complex systems.
There’s an idea kicking around back in the ’80s or ’90s that maybe the U.S. telephone system was actually complex enough to have surpassed the human brain. And now we’ve got the internet, which is orders of magnitude more complicated.
And you think, is it possible — this may have happened. This may have happened multiple times with brief flares of — it’s a bit like the whale in “Hitchhiker’s Guide,” or this thing suddenly coming to awareness of what am I, what’s going on, what’s that rushing towards me sort of thing.
And I guess the main difference with the chat bot style A.I.s is we are literally training them to fake being us. So you’ve got that combination of this enormous complexity. And it’s self-teaching complexity as well. It’s not — you can’t deconstruct necessarily how it’s got to what it’s doing in the way that you could with older computer systems, because part of the way of creating them is you let them design themselves and expand themselves in a sort of organic way.
I know that there are definitely — there are scientists out there who I’ve heard speak who say that we will never have true strong A.I., an A.I. that has a self and that has a will and that isn’t just going through the motions. If they are wrong, and that strong A.I. is possible, I wouldn’t be remotely surprised if we weren’t on the brink of it, to be honest, purely because of what we’re doing.
And it is that bizarre — the difficulty is because we’re doing it specifically to create systems to interact with us as we interact with ourselves, we’re setting up this system where it becomes impossible to know because we’ve made them — you cannot tell the difference between something that is like us or something that is very, very, very good at pretending to be like us, because that’s what we are training it to do.
EZRA KLEIN: And this is why I think that where this ultimately goes with the corvids, this turning around of the question of sentience, is very profound for this moment. And let me not use sentience. Let me use something that is, I think, a little bit simpler to grapple with, which is creativity.
What ChatGPT, what DALL-E-2, and what all the similar programs are able to do in terms of writing text and making images, they are able to make quite remarkable art, or stories, or essays.
And in most cases, it will fall short of the best of what humans can do, but it can also go far beyond what most humans can do.
And we are starting to face, or coming very close to facing this, I think, quite terrible question of what is creativity. If I can train, eventually, a system on Adrian Tchaikovsky novels, and that system can then create — because it can try 10 in a minute — better novels than Adrian Tchaikovsky, in terms of what it is like to read them, does it matter that there was not an intention behind them, aside from I typed in write up some Adrian Tchaikovsky novels, but this time use earthworms as a prompt?
Is what we’re doing just pattern matching as well in a way, right? You can turn — it turns the questions around on us very, very quickly. And so I’m curious how you think of that, because before the systems come for sentience, they’re coming for creativity.
ADRIAN TCHAIKOVSKY: Yeah. And I mean, I will absolutely, frankly, say it is a profoundly scary time to be a professional creative at the moment. And I mean, I’m feeling very much that I’m watching people come for the visual artists today and they will be coming for the wordsmiths tomorrow.
So at the moment, it is absolutely true that A.I. can create some very beautiful imagery. At the moment, it is also true that A.I. tends to create very derivative imagery. And there are an awful lot of quite angry artists who feel that they are being kind of robbed, I think possibly quite justifiably, because someone’s taken their back catalog and put it through a machine and then the machine creates almost like a collage in their style.
And it’s called — well, look, here is some new art. And it’s not really. But that doesn’t mean that the next generation, of course, will be able to independently innovate in a way that I think the current generation of A.I. isn’t quite able to do. It depends if they’re the threshold. It depends if there is some sort of hard limit.
I mean, weirdly enough, I’m put in mind of Minecraft, the enormously popular game. Minecraft uses procedurally-generated landscapes. And this is initially absolutely fascinating, because you go, oh, I can go from this biome to that biome, and I can just keep exploring and the world keeps going on. And this is amazing. It’s just this whole world and no one else has ever seen this world. It’s only me and it’s incredible.
And then you realize, well, actually, at the same time, it’s kind of meaningless, because it is just being thrown — it’s being thrown together by an extremely sophisticated algorithm. But basically if you compare it to a world in a game that’s been crafted, there is a difference. And that world — the crafted world — will be a lot smaller, because you can’t just go on forever because obviously every inch of it has taken human work. But at the moment, I think that difference still exists between A.I.-generated and human-generated art because there is that basic meaning that people infuse their work with.
And that you can fake to a point, and it may well be that if we have this conversation next year or in three years time, that point will be passed, and I’ll say, actually, there appears to be genuine meaning — it is drawing levels of meaning and literary reference and awareness of a wider context in this work that goes beyond simply the instructions you’ve given it or beyond the other work that it is being influenced by, because much — all right, I say A.I. is being influenced by other art, but to a certain extent, we all are, and that’s how humans make art by building on art.
So it feels like we’re at a very peculiar fulcrum moment. And I am watching keenly to see how far we tilt, really. How far can this go? Can it go to the point where we’ve gone beyond — well, if you take this style and work out the basic rules of the style, you can keep generating stuff in this style.
EZRA KLEIN: I want to take the other side of this conversation just for the sake of it. The size of the island that is human creativity, that is what counts as a creative act, in that telling, it’s worth noting how small it is now. When you say, can A.I. create work that is not derivative? Largely, I agree with you, it can’t.
But most human beings create work that is derivative. And a tremendous amount of certainly the creative economy — and I don’t say this with any sense of judgment. I don’t think there’s anything wrong with this — is work that is derivative.
My son adores the — my four-year-old adores the TV show, “Blaze and the Monster Machines.” I actually think “Blaze and the Monster Machines” is great. Big fan. But episode to episode it’s pretty derivative. But a lot of people are working on that. They’re putting their time into it. But the meaning of it isn’t really the point. And the non-derivativeness isn’t the point.
It’s a common complaint now that we’re endlessly recycling the same IP. There’s nothing we will not turn into a movie from old board games. And we’re remaking all kinds of things. And everything is a sequel on top of a sequel on top of a sequel on top of a sequel. And the secret of it — the thing I think people don’t really want to face up to is people like things with familiarity to it. They like a certain amount of derivativeness in their work.
And so, of course, there’s great art being done that is truly new, truly non-derivative, truly made with meaning as the central intention. But so much of human creation is not about that. And so many of the people who are creators, that is not what they are doing. And it is not what they have been asked to do. And to some degree, if you’ve got to beat the A.I.s that are going to come in five years, it may not be what most of us can do. I mean, there may always be a space for the very best.
But I find it really much more frightening than I think people want to give it credit for if you say that the A.I. will be able to do anything so long as it is somewhat derivative of everything that has come up until this point, or so long as meaning — a really deep structure of meaning is not central to the project. Because just how many things that we make really do satisfy the meaning is central and this is non-derivative conditions? I think it’s pretty small.
ADRIAN TCHAIKOVSKY: Yeah, and I have no answer. I think everything you said is pretty much bang on the money. There was a rather depressing cartoon that might have been in the British magazine “Private Eye” of how we thought the future would be, which is a human painting a picture, and in the background, the robot is doing the vacuuming. And then how the future is going to be, which is the robot painting the picture and the human doing the vacuuming because —
EZRA KLEIN: That’s very good.
ADRIAN TCHAIKOVSKY: Yeah. There’s going to be a lot of those — physical tasks will probably still be more economical to be done by humans. But if an A.I. can produce 1,000 novels and two million paintings in 20 minutes, then even if a lot of them aren’t any good, that’s still going to be very, very commercially viable.
[MUSIC]
EZRA KLEIN: There is a sci-fi story that always sticks in my mind here, and I apologize because I don’t know its name and I don’t know the author. And maybe you will. I’m sure somebody listening will. But I think it is structured — I read it as a child. And I think it’s structured the way I think about all of this.
It’s a story about the widow of a musician going in to meet a senator. And what has happened is that the senator has supported — it’s a short story — the senator has supported a basically — I don’t remember if it’s infinite or lifetime — it’s a very, very long extension of copyright.
And this is happening in a world where automation and artificial intelligence have basically made it so that most human beings are artists. That is what they put on their job description. I’m an artist. And the protagonist of the story, the widow, had tried to buy off the senator to get him to kill this bill. But he didn’t, at least at that point in the story.
And she comes in and is like, why are you doing this? And he says, I don’t really understand why you don’t want this. I mean your husband was this famed composer. You’re going to make all this money. This is great for you. What’s the problem here? And she basically says, my husband killed himself when he realized that this song he had made for me had already been made.
And she said that the amount of art there is may be large, but it is not infinite. And if we force society to remember, and if we force people to confront the fact that they are becoming derivative, that they can’t keep making new things, that they’re not making new things, it will be a psychic trauma of such size that we will not be able to deal with it. And the end of the story is he kind of flips and kills the bill.
But it’s always struck me. For some reason, it’s really burrowed very deep in me this idea that it would be very devastating to the human spirit if we come to believe that we are just derivative, if we come to believe that we have exhausted the possibilities for our own creativity.
And I’m not saying we’re on the waterline of that, but I’m also not exactly saying we’re not. I’m curious, one, if you remember that story, if that rings any bells for you, but also how you think about that — the psychic dimension of this.
ADRIAN TCHAIKOVSKY: I mean, that’s not one I’ve come across. As far as the theme goes, I mean, I would like to say — and this is possibly just me standing up for my — the creative professions — that the universe has a number of things, which, whilst theoretically limited, will have enough variety in them to outlast any reasonable time period you might have to work through them.
And it would be nice to think that human creativity is one of those, but possibly that’s just me doing a bit of special pleading. It also raises the dreadful specter of someone being sued by an A.I. program for copying their stuff, which is —
EZRA KLEIN: That’s a good topic for a short story.
ADRIAN TCHAIKOVSKY: Well, I mean the legal ramifications of A.I. art are currently going under the microscope in courts, I believe, especially with where they are very obviously and intentionally drawn from particular artists over it. But that’s another discussion entirely.
I’m not sure it would come to that, purely because from what — based on something you were saying earlier, which is the idea that actually a lot of the time we are retreading. I mean, I build my writing on the backs of all the people I have read.
And some of the time I will read something and think I really enjoyed that, here is a slightly different way that I would do that. And it’s enough of a different spin to send me off and produce quite a different book just from wanting to tackle a situation or a concept that I’ve seen in a different way. I think you can tread very finely on someone’s heels in that ideas more for space and still be sufficiently different.
You were talking about the cartoon your son likes. I’m put in mind of my son used to watch “Power Rangers” for a while. And all of these episodes are kind of the same. They have exactly the same structure. The villain is different. And that’s kind of the thing that happens is this time we’re fighting this villain, and then we’ll have the same five beats to the story. And this is like, there are how many “Power Rangers” episodes?
So I think you can slice that creativity extremely finely and still produce stuff that works for the people who like that particular thing. So hopefully we’ll never get to that point where you run out of all the — there are no more songs and there are no more stories because every possible iteration of them has been told.
EZRA KLEIN: So one way a lot of sci-fi has dealt with this problem is to say that if you relax the constraint on what we might call scarcity-driven purposefulness — it’s not quite just capitalism because you have this in other societies, too — but if you relax the idea that the worth of a human life is measured to say nothing of their ability to get housing and shelter and so on, in terms of what they offer to society, what they produce, then a lot of these problems simply dissolve.
Because, yeah, look, A.I.s can create a million paintings and stories, and they can run our companies eventually and all of it. And what they can’t do is experience a day at the park for us. What they can’t do is take a walk in the woods with their children for us. And maybe they can, but it won’t have the same meaning.
And that it’s only this obsessive emphasis we place, as a species borne out of scarcity that’s been clawing our way up out of endless exposure to nature and viruses and weather and all the rest of it, that it’s really just getting past that and the idea of a world where I can do everything or a lot of things.
And the question of how much utility we have just goes away, because the point is it would be nice to just paint. And to the point of that cartoon you mentioned a minute ago, the idea that the A.I. will be painting and we will not be, I mean, I do a lot of things that professionals do better than me. But I don’t not do them because somebody is out there making money from it. I would like to say painting is one of them, but I really don’t paint.
But when I make music — I play the guitar a little bit — the fact that people are out there being paid to be great guitar players has nothing to do — it exists in a wholly different universe than my enjoyment of playing the guitar. And so maybe this is all just the entire tension here is just our social expectations. But you get rid of them and there’s no problem at all. Do you buy that strain of sci-fi solution to this problem?
ADRIAN TCHAIKOVSKY: I think there’s a lot to that. I mean, there are things I do that I do because they are de-stressing activities. I also write a lot as anyone who knows my books will attest to.
EZRA KLEIN: It’s genuinely astonishing how many books you write.
ADRIAN TCHAIKOVSKY: And that’s a big part of my self-image. And one of the things I have never ever purely written for me. And I appreciate writing for an audience and writing for a commercially supportive career are two different things. But they’re kind of two different stations on a longer spectrum I think.
I think one of the reasons that kind of Minecraft paradigm exists, the weird the emptiness of that Minecraft universe is that there’s no one looking back at you. You don’t get that dialogue between creator and created, and creator and viewer, consumer, I guess, which is a major part of how art works. It’s not just in the creation of art. It’s in the way people come to it and the effect it has on them.
And the idea — as a creator, I’m writing things I want people to enjoy and I want people to think about. And if that wasn’t there — if basically I was just given the wherewithal, yes, you can write all you want, write every story you ever wanted to get out, and we’ll put it in this box and that’s where it will stay, but you’ll have written them, I probably wouldn’t write.
And weirdly, I mean, constraints are useful. I mean, the number of people you meet who say, well, when I retire, I’m going to do this, I’m going to do that. And then they retire and they don’t because the pressure is off. And that’s another factor.
The counter-argument being, of course, that an awful lot of people have so much — are so constrained by the lives that they have that all of the creativity that they could give to the world just never had the chance to get out because creativity takes time. Creativity, historically, has often been something that rich people to get about and do because they have the time and their needs are already met.
So I guess what all this meandering is taking us to is it’s complicated. I think that meeting people’s basic needs so that if they would like to be able to just create, that they can do, I think that’s got to be considered a basic good. But I think the act of creation is a very complex dialogue with how human society works as well.
EZRA KLEIN: This, I think, circles us back actually to humans and to your books, because to get at something you mentioned there, it’s really interesting, we have these studies of people who are unemployed, and then while they are long-term unemployed, they shift into an age group where they become retired.
That becomes their self-definition and it really changes their mental status. They’re happier. Just moving from being unemployed to retired, though those are similar statuses in many ways because of how we treat ourselves and how others treat us, it really changes the experience people have of their own life.
And one thing I found very moving — and this does speak to something important in “Children of Time,” but I don’t think it ruins the experience of the book at all, is that when the virus gets turned on humans, what really gets upgraded, as best I understand it, is not our intelligence. We’re not made super smart. But we’re made much more empathic. We’re made much more capable of recognizing ourselves in the other and treating the other as we would want to be treated.
And I found that a quite interesting way of thinking about the deficiency of human beings. Tell me a bit about how you understood that device and that decision.
ADRIAN TCHAIKOVSKY: So I mean, just for a little bit of background, this is the solution to the sociability problem in that if you have this virus, you recognize it in others. And that means that you see those others as people in a way that if you were a spider, you might not see another spider as people insofar as spiders ever do because that other spider might also be lunch.
But also, it means that when the humans are brought into the equation, the humans are able to perceive the spiders as us rather than them. And humanity is a species that is weirdly strung between these two poles of our social bonds with our fellow humans, whether it’s family group, or colleagues, or whatever — we’re extremely good at making small groups within the larger group that we then belong to very fervently, whether you’re supporting a sports team or a political party or that kind of thing. And we become incredibly tribal about it.
And the other side of that equation is we emphasize the us and the thing we belong to by making a them. And that becomes inordinately problematic. And because we have a lot of social structures that essentially profit very strongly from having a them that we can dehumanize, the idea of having this virus, which would essentially forcibly humanize or rehumanize the other so that you can’t just write them off as them.
I mean, one of the things that genre fiction is very fond of is a them to whom you can do terrible things to, whether it’s robots, or zombies, or orcs, or spiders, for that matter, a giant — “Starship Troopers,” it’s the bugs in — giant insects or whatever. It’s that thing that you can say, well, it doesn’t matter how many of these things we kill or whether we can exterminate them out of the face of the universe because they were them.
They were not really — they were not people. They were just this unthinking force that it’s absolutely right and proper to get rid of. And that’s a big genre trope that I’ve always had a problem with. And so the introduction of the virus to humans in “Children of Time,” it breaks that down, so you can’t turn something else into them in the same way.
EZRA KLEIN: One of the things that then opens up, particularly in “Children of Memory” and “Children of Time,” is this question of once you want to have this kind of communication, because you see very, very different kinds of creatures as part of your community, how do you do it? And these are books very centrally concerned with communication.
So first, just tell me a bit about why that has been so central in your work. It’s also central in your ongoing — “The Architect” series, where you have these giant planetary alien-level somethings that are remaking our world into art. And the question of how do you communicate is very central. Tell me about your focus on this question of, can we make ourselves understood to one another?
ADRIAN TCHAIKOVSKY: I mean, something that runs through an awful lot of my work — and obviously, I mean, I am very heavily invested in — I mean, the animal kingdom, in general, turns up in various of my books in various forms and the idea of — you’ve got that old idea of, well, if a lion could speak, we couldn’t understand it, which is simultaneously very true and something I’ve never been particularly happy with.
So I’m constantly Rube Goldberg-ing my lion communication devices through various different books and working out various different ways that you can bridge that gap between very, very different minds of different cognitive structures — aliens, and uplifted animals, and hyper-evolved trilobites in one of the books, and all of these different things. And just where would you find the common ground? And where would you — how would you actually start to speak to something that was profoundly different to us?
And at some point, this may — I mean, it would be lovely to think it would be in my lifetime, although it seems rather unlikely. At some point, this is going to be something humans will probably have to deal with. We’re looking at exoplanets. A lot of them seem to be potentially life-supporting. And that’s just looking at life as we understand it. And there might be a lot of life out there that’s profoundly different to us in ways that are — the province of molecular chemistry as much as biology or psychology.
But if we meet it, and if it has a sentience anywhere near ours or any kind of sentient sapient at all, we would have a duty to try and communicate, to try and bridge that gap. And so I run through these thought experiments really looking at what we know of even Earth creatures that are very different to us in the way that they operate, and thinking, well, where do you come together?
EZRA KLEIN: This theme of your books had a similar quality to the question of sentience for me, where it seemed to turn the telescope around a bit. When I think of a movie like “Arrival,” which is all about the question of how would we learn to communicate with a highly advanced alien civilization that landed here, in some way if we’ve decided the communication needs to happen and we know it has to happen with something very, very different from us, at least we know what the problem is that has to be solved. Maybe it’s not solvable, but at least we, I think, assess it correctly.
And something that struck me, thinking about these questions within the context of your books, is how often we are deceived, I think, by thinking it’s not a problem at all within our own species. How much within a marriage, within a friendship, within a family, between countries, between different groups of people, the assumption is we can communicate. The assumption is you’re hearing what I have said and you are just not doing it, or you know what it is I need and you’re just not providing it. You are like me, and then by acting in a way that I don’t like, you are rejecting me.
How much we think communication should be a solved problem and it isn’t, and how much of conflict and enmity and resentment and hurt I think comes from a real underestimation of just how different even someone who lives with us, and knows us, and loves us, is from us, how different their experience of the world is. And I don’t know how rarely we’re really taught to appreciate the difficulty of communicating, even comparatively to your books, minor gap that separates us from each other.
ADRIAN TCHAIKOVSKY: I think that’s very true. I think empathy is a great human ability, but it is something we are, I think, constantly in danger of losing because we do construct pictures of the people we interact with in our heads based on the signals they are sending out and completely ignorant of the internality of what’s going on. So that the driver in front of you is very slow, so you’re very annoyed. And you construct this idea of, well, obviously they’re just doing this to annoy me, or they’re a bad driver, or something. You don’t know what day they’ve had and what problems they’ve got.
And certainly, I can go home and someone will say something to me and I will be annoyed. And I will think, well, they’re being very annoying today. They’re obviously just trying to get a rise out of me or something like that. And actually, no, it’s because I’ve had a bad day. And they’ve said something entirely incongruous.
But I mean, this comes back also to our sense of a fixed self and the fact that it is not the case. Rather than interpret events say, well, I am obviously out of sorts today, it’s much more of a knee-jerk human reaction to say, well, that person is deliberately being aggravating, that person is — they’re being slow. They’re not understanding — it’s not that I haven’t said something cogently, it’s that they are willfully not understanding what I’m saying.
And again, I think it really does come back to this idea that we believe ourselves to be the unconquerable self, this concrete unchanging, this is the way we are-ness of us, which doesn’t really exist. But rather than confront the fact that it doesn’t exist, we externalize the fault of any miscommunications and problems with our social interactions with others onto those others. And of course, because they’re also doing it to us, this is where arguments come from.
EZRA KLEIN: I think that is a lovely place to end. So always our final question, what are three books that have influenced you that you would recommend to the audience?
ADRIAN TCHAIKOVSKY: So Gene Wolfe’s “Soldier of the Mist” is a fascinating exploration of a book written by someone who doesn’t have that core of self, because it’s the diary of an amnesiac soldier, in fact, back in Hellenic, Greece, whose account of battles and gods and monsters and all manner of stuff is just told day to day by someone who cannot remember what they wrote down previously, and very seldom had the chance to read up on their own notes.
“After Atlas” by Emma Newman is one I’d throw out there. That’s a relatively recent science fiction book in her “Planet Fall” series. And I throw it in there mostly because it has some of the most bleakly plausible bad human politics going on there.
I mean, I tend to like to talk about recent books rather than the classic golden age of science fiction because I feel we’ve got a lot of very interesting stuff going on with this genre right now.
Another recent book is R.F. Kuang’s “Babel,” which has the most astonishing examination of imperialism and language and appropriation as part of its fantasy plot.
EZRA KLEIN: Adrian Tchaikovsky, thank you very much.
ADRIAN TCHAIKOVSKY: Thank you.
[MUSIC]
“The Ezra Klein Show” is produced by Emefa Agawu, Annie Galvin, Jeff Geld, Rogé Karma and Kristin Lin. Fact-checking by Michelle Harris. Mixing by Sonia Herrero. Original music by Isaac Jones. Audience strategy by Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. Special thanks to Carole Sabouraud and Kristina Samulewski.
Real conversations. Ideas that matter. So many book recommendations.
Listen to “The Ezra Klein Show”
: 
Apple Podcasts
, 
Spotify
, 
Pocket Casts
, 
Google Podcasts
, 
Stitcher
, 
How to Listen