To the Editor:
Re “
How ChatGPT Hijacks Democracy
,” by Nathan E. Sanders and Bruce Schneier (Opinion guest essay, nytimes.com, Jan. 15):
I fed this essay into ChatGPT and asked it to write a rebuttal. ChatGPT read the article and wrote the following in less than a minute:
As a writer and researcher who is familiar with the capabilities of language models like ChatGPT, I was surprised to read the recent New York Times essay that suggested that this technology could be used to “upend” democratic processes through lobbying.
While it is true that ChatGPT can generate text that is often indistinguishable from human writing, it is important to note that this technology is not capable of understanding the nuances and subtleties of political networks and systems.
Additionally, the idea that ChatGPT could be used to “ruthlessly exploit” policymaking vulnerabilities is a gross exaggeration of its capabilities.
Furthermore, it is important to note that the problem of automatically generated comments is not new. For several years, we have struggled with bots that automatically post content. Platforms like Facebook have become better at removing “coordinated inauthentic behavior.”
In reality, ChatGPT and similar technologies have the potential to be powerful tools for businesses, researchers and educators. They can be used to automate repetitive tasks, improve efficiency and generate new insights. However, the notion that ChatGPT could be used to compromise democratic processes is fear-based speculation that is not rooted in reality.
It is important to approach new technologies with caution and to understand their capabilities and limitations. However, it is also essential not to exaggerate their potential dangers and to consider how they can be used in a positive and responsible manner.
OpenAI’s ChatGPT
(via Gary Apple)
New York